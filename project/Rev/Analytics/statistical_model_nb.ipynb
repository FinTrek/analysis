{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yennanliu/anaconda3/envs/ds_dash/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/yennanliu/anaconda3/envs/ds_dash/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# python 3 \n",
    "# load library \n",
    "# op \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# ML \n",
    "from sklearn.cross_validation import train_test_split, KFold, cross_val_score\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# help function \n",
    "# ---------------------------------\n",
    "# OP \n",
    "\n",
    "def load_data():\n",
    "\tdf = pd.read_csv('kc_house_data.csv')\n",
    "\treturn df \n",
    "\n",
    "def get_linearmodel_col(df):\n",
    "    cols = ['price',\n",
    "            'sqft_living',\n",
    "            'sqft_lot',\n",
    "            'sqft_above',\n",
    "            'sqft_basement']\n",
    "    return df[cols]\n",
    "    \n",
    "    \n",
    "def data_clean(df):\n",
    "    df_ = df[(df['price'] < df['price'].quantile(0.97))&\n",
    "     (df['price'] > df['price'].quantile(0.03))]\n",
    "    print (' data count (before clean) : ', len(df))\n",
    "    print (' data count (before clean) : ', len(df_))\n",
    "    return df_ \n",
    "\n",
    "\n",
    "def feature_extrace(df):\n",
    "\tpass \n",
    "\n",
    "def get_train_test_set(df):\n",
    "    X = df[['sqft_living',\n",
    "         'sqft_lot',\n",
    "         'sqft_above',\n",
    "         'sqft_basement']]\n",
    "    y = df['price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    return X_train,y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def get_train_test_set_V2(df):\n",
    "    X = df.iloc[:,3:]\n",
    "    y = df['price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    return X_train,y_train, X_test, y_test\n",
    "    \n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ML \n",
    "\n",
    "def linear_model(X_train,y_train,X_test,y_test,model):\n",
    "    model.fit(X_train,y_train)\n",
    "    print ('---  train score ---')\n",
    "    print (model.score(X_train,y_train ))\n",
    "    print ('--- intercept_  --- ')\n",
    "    print(model.intercept_)\n",
    "    print ('--- coef_ --- ')\n",
    "    print(model.coef_)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    print ('--- mean_squared_error --- ')\n",
    "    print (mean_squared_error(y_test_predict, y_test))\n",
    "    print ('--- r2_score --- ')\n",
    "    \"\"\"\n",
    "    Best possible score is 1.0 \n",
    "    and it can be negative (because the model can be arbitrarily worse). \n",
    "    A constant model that always predicts the expected value of y, \n",
    "    disregarding the input features, would get a R^2 score of 0.0.\n",
    "    \"\"\"\n",
    "    print (r2_score(y_test_predict, y_test))\n",
    "    return y_test_predict \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def linear_model_evaluate(y_test_predict,y_test):\n",
    "    # https://www.scipy-lectures.org/packages/statistics/index.html\n",
    "    from matplotlib import pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy import stats\n",
    "    #%matplotlib inline\n",
    "    print (' --- scatter plot --- ')\n",
    "    x = range(0,int(max(y_predict)))\n",
    "    y = x \n",
    "    plt.scatter(np.array(y_test),y_test_predict)\n",
    "    plt.plot(x,y)\n",
    "    print (' --- histagram plot --- ')\n",
    "    plt.hist(y_test_predict, alpha = .5)\n",
    "    plt.hist(np.array(y_test) , alpha = .5)\n",
    "    plt.legend(['predict', 'true'])\n",
    "    print (' --- hypothesis test --- ')\n",
    "\n",
    "\n",
    "def statistics_linear_model(X_train,y_train,X_test,y_test):\n",
    "    # https://machinelearningmastery.com/parametric-statistical-significance-tests-in-python/\n",
    "    # https://www.ritchieng.com/machine-learning-evaluate-linear-regression-model/\n",
    "    \"\"\"\n",
    "    *** Model evaluate \n",
    "     Mean Absolute Error (MAE)\n",
    "     Mean Squared Error (MSE) \n",
    "     Root Mean Squared Error (RMSE)\n",
    "    \"\"\"\n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    print(results.summary())\n",
    "    y_test_pred = results.predict(X_test)\n",
    "    print (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "    print (r2_score(y_test_pred, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data count (before clean) :  21613\n",
      " data count (before clean) :  20311\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.888\n",
      "Model:                            OLS   Adj. R-squared:                  0.888\n",
      "Method:                 Least Squares   F-statistic:                 3.596e+04\n",
      "Date:                Mon, 16 Jul 2018   Prob (F-statistic):               0.00\n",
      "Time:                        03:31:09   Log-Likelihood:            -1.8444e+05\n",
      "No. Observations:               13608   AIC:                         3.689e+05\n",
      "Df Residuals:                   13605   BIC:                         3.689e+05\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "sqft_living     157.1101      1.074    146.229      0.000     155.004     159.216\n",
      "sqft_lot         -0.1439      0.040     -3.567      0.000      -0.223      -0.065\n",
      "sqft_above       83.9615      1.572     53.427      0.000      80.881      87.042\n",
      "sqft_basement    73.1485      2.502     29.240      0.000      68.245      78.052\n",
      "==============================================================================\n",
      "Omnibus:                      692.649   Durbin-Watson:                   1.986\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1098.428\n",
      "Skew:                           0.437   Prob(JB):                    3.02e-239\n",
      "Kurtosis:                       4.083   Cond. No.                     5.95e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.06e-21. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "188124.63570036867\n",
      "0.022297366744175373\n"
     ]
    }
   ],
   "source": [
    "# model V1 \n",
    "df = load_data()\n",
    "df_ = data_clean(df)\n",
    "df_ = get_linearmodel_col(df_)\n",
    "X_train,y_train, X_test, y_test = get_train_test_set(df_)\n",
    "statistics_linear_model(X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments : model V1 \n",
    "This is a simple linear model only train with *** 4 variables (sqft_living/ sqft_lot / sqft_above / sqft_basement)***  which are the variables I think may be strong co-releated to the prices. data preprocess includes one data cleaning process, no feature engineering / re-scale / super parameter tuning  ..\n",
    "> - sqft_living/ sqft_above / sqft_basement are  positively associated with prices \n",
    "- sqft_lot is slightly negatively associated with prices \n",
    "- sqft_living/ sqft_lot / sqft_above / sqft_basement all have small P-values\n",
    "-  The linear model works OK on train set (R-squared =  0.888), but not work very well on test set (R-squared =  0.022). Need to re-check data quality such as outlier/feature selection / multicollinearity ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data count (before clean) :  21613\n",
      " data count (before clean) :  20311\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.947\n",
      "Model:                            OLS   Adj. R-squared:                  0.947\n",
      "Method:                 Least Squares   F-statistic:                 1.429e+04\n",
      "Date:                Mon, 16 Jul 2018   Prob (F-statistic):               0.00\n",
      "Time:                        03:31:15   Log-Likelihood:            -1.7934e+05\n",
      "No. Observations:               13608   AIC:                         3.587e+05\n",
      "Df Residuals:                   13591   BIC:                         3.589e+05\n",
      "Df Model:                          17                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "bedrooms      -9120.2125   1496.270     -6.095      0.000   -1.21e+04   -6187.317\n",
      "bathrooms      2.173e+04   2635.895      8.244      0.000    1.66e+04    2.69e+04\n",
      "sqft_living      52.9076      1.918     27.582      0.000      49.148      56.668\n",
      "sqft_lot          0.2057      0.041      5.056      0.000       0.126       0.285\n",
      "floors         3.817e+04   2865.936     13.318      0.000    3.26e+04    4.38e+04\n",
      "waterfront     1.312e+05    1.8e+04      7.269      0.000    9.58e+04    1.67e+05\n",
      "view           3.969e+04   1779.468     22.304      0.000    3.62e+04    4.32e+04\n",
      "condition      2.492e+04   1892.842     13.168      0.000    2.12e+04    2.86e+04\n",
      "grade           8.07e+04   1757.795     45.908      0.000    7.73e+04    8.41e+04\n",
      "sqft_above       23.4820      1.880     12.493      0.000      19.798      27.166\n",
      "sqft_basement    29.4256      2.161     13.615      0.000      25.189      33.662\n",
      "yr_built      -2018.7530     55.492    -36.379      0.000   -2127.524   -1909.982\n",
      "yr_renovated     15.8927      3.017      5.268      0.000       9.979      21.806\n",
      "zipcode        -320.8585     14.506    -22.119      0.000    -349.293    -292.424\n",
      "lat            5.545e+05   8577.735     64.647      0.000    5.38e+05    5.71e+05\n",
      "long          -6.989e+04   1.07e+04     -6.549      0.000   -9.08e+04    -4.9e+04\n",
      "sqft_living15    50.3857      2.857     17.637      0.000      44.786      55.985\n",
      "sqft_lot15       -0.2250      0.060     -3.724      0.000      -0.343      -0.107\n",
      "==============================================================================\n",
      "Omnibus:                     1999.043   Durbin-Watson:                   1.988\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5368.361\n",
      "Skew:                           0.808   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.618   Cond. No.                     2.97e+17\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.56e-21. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "129777.72763270323\n",
      "0.53165413915778\n"
     ]
    }
   ],
   "source": [
    "# model V2 \n",
    "df = load_data()\n",
    "df_ = data_clean(df)\n",
    "X_train,y_train, X_test, y_test = get_train_test_set_V2(df_)\n",
    "statistics_linear_model(X_train,y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments :  model V2\n",
    "This is a  linear model  train with *** all variables which is the comparison model with the V1 above ***. data preprocess includes one data cleaning process, no feature engineering / re-scale / super parameter tuning  ..\n",
    "> - sqft_living/ sqft_above / sqft_basement / sqft_living15 / bathrooms / condition.. are positively associated with prices \n",
    "- Variables like bedrooms/ yr_built / ... are srong negatively associated with prices which is intertesting part to dig in  \n",
    "- All variables have small P-values\n",
    "-  The linear model works \"too good\"  on train set (R-squared =  0.947), need to double check if \"over-fitting\" on \n",
    "train set, one of the clue is the \"multicollinearity\" warnings from model output\n",
    "- The linear model works better in test set than V1 model above(R-squared =  0.53), but still not good enough.\n",
    "Will need to do much data clean/ feature engineeting to optimize the linear model \n",
    "Or,  can try some non-linear model instead (i.e. SVM/DT/ ...) (in case non-linear data )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_ds_dash)",
   "language": "python",
   "name": "conda_ds_dash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
