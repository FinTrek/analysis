{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "L1, L2 regularization are 2 closely techniques that can be used by reducing ***over-fitting*** problem in machine learning. \n",
    "\n",
    "The ***loss Function*** known as (error = $expectations(y(predict) - y(true))$) can be modified by L1, L2 regularization  by adding \n",
    "the ***extra*** L1, L2 term :\n",
    "\n",
    "- L1 regularization\n",
    "    - error = $expectations(y(predict) - y(true))**2$) +  λ*sigma(|beta_i|)\n",
    "\n",
    "- L2 regularization\n",
    "     - error = $expectations(y(predict) - y(true))**2$) +  λ*sigma((beta_i)**2)\n",
    "     \n",
    "Both these 2 approached can reduce over-fitting in cases, but the modified model accuracy and computing speed may be big differences sometime, we will discuss further about how to obtain L1, L2 terms, the relation between L1, L2, and learning rate in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# analysis library\n",
    "import pandas as pd, numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "# ML\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
